{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "zero=torch.zeros(1,1)\n",
    "endtime=time.time()\n",
    "\n",
    "time_spent=endtime-start_time\n",
    "print(f\"{time_spent:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time spend for cuda is 0.01000023\n",
      "total time spent for cpu is 0.11475897\n",
      "CPU times: total: 2.23 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch_rand1=torch.rand(100,100,100,100).to(device)\n",
    "torch_rand2=torch.rand(100,100,100,100).to(device)\n",
    "\n",
    "np_rand1=torch.rand(100,100,100,100)\n",
    "np_rand2=torch.rand(100,100,100,100)\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "rand=(torch_rand1 @ torch_rand2)\n",
    "\n",
    "endtime=time.time()\n",
    "\n",
    "print(f\"total time spend for {device} is {(endtime-start_time):.8f}\")\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "rand=np.multiply(np_rand1,np_rand2)\n",
    "endtime=time.time()\n",
    "\n",
    "print(f\"total time spent for cpu is {(endtime-start_time):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "#defining a probablity distribution\n",
    "probablities=torch.tensor([0.1,0.9])\n",
    "#using multinomial distribution to have 10 samples\n",
    "samples=torch.multinomial(probablities, num_samples=10, replacement=True)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#to concatenate two tensors\n",
    "tensor2=torch.tensor([1, 2, 3, 4])\n",
    "output=torch.cat((tensor2, torch.tensor([5])), dim=0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#to generate a lower triangle matrix \n",
    "output=torch.tril(torch.ones((5, 5)))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# to generate a upper triangle matrix\n",
    "output=torch.triu(torch.ones(5,5))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#generating a matrix on which after performing exponenting we get above result\n",
    "output=torch.zeros(5, 5).masked_fill(torch.tril(torch.ones(5,5)) == 0, float('-inf'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preforming exponent of above result\n",
    "torch.exp(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the input file is: torch.Size([2, 3, 4])\n",
      "the sahpe of the output file is: torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "inputfile=torch.zeros(2, 3,4)\n",
    "#below we swap the zero dimension with the 2nd dimension\n",
    "output=inputfile.transpose(0, 2)\n",
    "print(f\"the shape of the input file is: {inputfile.shape}\")\n",
    "print(f\"the sahpe of the output file is: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 5,  6,  7],\n",
      "        [ 8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "tensor1=torch.tensor([1,2,3])\n",
    "tensor2=torch.tensor([5,6,7])\n",
    "tensor3=torch.tensor([8,9,10])\n",
    "\n",
    "#stacking the tensor along a new dimension\n",
    "stacked=torch.stack([tensor1, tensor2, tensor3])\n",
    "print(stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=3, out_features=3, bias=False)\n",
      "tensor([-4.2634, -9.1410, -3.3415], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# nn has learnable parameters\n",
    "samples=torch.tensor([10.0,10.0, 10.0])\n",
    "linear_nn=nn.Linear(3,3,bias=False)\n",
    "print(linear_nn)\n",
    "print(linear_nn(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as ff\n",
    "#create a tensor\n",
    "samples=torch.tensor([10.0,10.0, 10.0])\n",
    "#appling softmax function \n",
    "softmax_fun=ff.softmax(samples, dim=0)\n",
    "print(softmax_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6])\n",
      "tensor([[ 1.7101, -1.0789, -0.4399,  0.2166,  2.9369, -0.2715],\n",
      "        [-0.6008,  0.2324, -0.3845,  0.3382,  1.0286,  0.8563],\n",
      "        [ 1.8161,  0.9672,  0.0688, -0.3312, -0.5676,  0.1047],\n",
      "        [ 1.3587, -2.6485,  1.2132, -2.1391,  1.4979, -1.0197]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an embedding layer\n",
    "vocab_size = 80\n",
    "embedding_dim = 6\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Create some input indices\n",
    "input_indices = torch.LongTensor([1, 5, 3, 2])\n",
    "\n",
    "# Apply the embedding layer\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "# The output will be a tensor of shape (4, 100), where 4 is the number of inputs\n",
    "# and 100 is the dimensionality of the embedding vectors\n",
    "print(embedded_output.shape)\n",
    "print(embedded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
